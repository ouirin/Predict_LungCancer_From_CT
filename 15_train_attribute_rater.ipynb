{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f388ab-a318-4167-ab4e-324158397a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import ntpath\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD \n",
    "from keras.metrics import mean_absolute_error\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.layers import Input, AveragePooling3D, Convolution3D, MaxPooling3D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ce705-c2c8-4de9-90ad-8fdf4983a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "trainset, testset = load_data()\n",
    "\n",
    "train_gen = data_generator(batch_size, trainset, need_augment=True)\n",
    "\n",
    "test_gen = data_generator(batch_size, testset, need_augment=False)\n",
    "\n",
    "learnrate_scheduler = LearningRateScheduler(step_decay)\n",
    "\n",
    "model = get_net(load_weight_path=None)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"G:/LungCancerPredict/model/\" + \"{epoch:02d}-{val_loss:.4f}.hd5\", monitor='val_loss', period=1)\n",
    "\n",
    "model.fit_generator(train_gen, int(len(trainset)/batch_size), 10, validation_data=test_gen, nb_val_samples=int(len(testset)/batch_size), callbacks=[checkpoint, learnrate_scheduler])\n",
    "\n",
    "model.save(\"G:/LungCancerPredict/model/the_end.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66fe8d-8dcb-427d-a90f-0d5e5d870cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_ratio=20):\n",
    "    \n",
    "    samples = glob.glob(\"G:/LungCancerPredict/extracted/lidc_extracted_image/*.png\")\n",
    "    random.shuffle(samples)\n",
    "    print(len(samples))\n",
    "\n",
    "    #从文件名解析标签\n",
    "    dataset = []\n",
    "    for index, sample_path in enumerate(samples):    \n",
    "    \n",
    "        file_name = ntpath.basename(sample_path)\n",
    "\n",
    "        parts = file_name.split(\"_\")\n",
    "    \n",
    "        subtlety_label = float(parts[-3]);      lobulation_label = float(parts[-4]); internal_structure_label = float(parts[-5])\n",
    "        calcification_label = float(parts[-6]); texture_label = float(parts[-7]);    spiculation_label = float(parts[-8])\n",
    "        margin_label = float(parts[-9]);        sphericiy_label = float(parts[-10]); malignacy_label = float(parts[-11])\n",
    "        diameter_label = float(parts[-12])\n",
    "\n",
    "        dataset.append((sample_path, diameter_label, malignacy_label, sphericiy_label, margin_label, spiculation_label, texture_label, calcification_label, internal_structure_label, lobulation_label, subtlety_label))\n",
    "\n",
    "    counter = int(len(dataset) * ((100-test_ratio) / 100.0))\n",
    "    dataset_train = dataset\n",
    "    dataset_test = dataset[counter:]\n",
    "    \n",
    "    print(\"Train count: \", len(dataset_train), \", Test count: \", len(dataset_test))\n",
    "   \n",
    "    return dataset_train, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd5055-c041-4686-99a6-e03a656b8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size, record_list, need_augment):\n",
    "    \n",
    "    random_state = numpy.random.RandomState(999)\n",
    "\n",
    "    if need_augment: random.shuffle(record_list)\n",
    "    \n",
    "    #按照batch_size动态生成数据    \n",
    "    img_list = [];           diameter_list = [];   \n",
    "    subtlety_list = [];      lobulation_list = []; internal_structure_list = []\n",
    "    calcification_list = []; texture_list = [];    spiculation_list = []\n",
    "    margin_list = [];        sphericiy_list = [];  malignacy_list = []\n",
    "    crop_size = 32;          batch_counter = 0\n",
    "\n",
    "    for index, record in enumerate(record_list):\n",
    "        \n",
    "        subtlety_label = record[10];     lobulation_label = record[9]; internal_structure_label = record[8] \n",
    "        calcification_label = record[7]; texture_label = record[6];    spiculation_label = record[5] \n",
    "        margin_label = record[4];        sphericiy_label = record[3];  malignacy_label = record[2] \n",
    "        diameter_label = round(record[1],4) \n",
    "                     \n",
    "        cube_image = load_cube_img(record[0], 8, 8, 64)\n",
    "\n",
    "        if need_augment:\n",
    "            wiggle_indent = crop_size / 4\n",
    "            wiggle = 64 - crop_size - crop_size / 2 - 1\n",
    "            indent_x = int(wiggle_indent + random.randint(0, wiggle))\n",
    "            indent_y = int(wiggle_indent + random.randint(0, wiggle))\n",
    "            indent_z = int(wiggle_indent + random.randint(0, wiggle))\n",
    "        else:\n",
    "            indent_x = int((64 - crop_size) / 2)\n",
    "            indent_y = int((64 - crop_size) / 2)\n",
    "            indent_z = int((64 - crop_size) / 2)\n",
    "\n",
    "        cube_image = cube_image[indent_z:indent_z + crop_size, indent_y:indent_y + crop_size, indent_x:indent_x + crop_size]\n",
    "\n",
    "        if need_augment:\n",
    "            if random.randint(0, 100) > 50: cube_image = numpy.fliplr(cube_image)\n",
    "            if random.randint(0, 100) > 50: cube_image = numpy.flipud(cube_image)\n",
    "            if random.randint(0, 100) > 50: cube_image = cube_image[:, :, ::-1]\n",
    "            if random.randint(0, 100) > 50: cube_image = cube_image[:, ::-1, :]\n",
    "        \n",
    "        img3d = normalize_and_expand(cube_image)\n",
    "                \n",
    "        img_list.append(img3d);                        diameter_list.append(diameter_label)  \n",
    "        subtlety_list.append(subtlety_label);          lobulation_list.append(lobulation_label); internal_structure_list.append(internal_structure_label) \n",
    "        calcification_list.append(calcification_label);texture_list.append(texture_label);       spiculation_list.append(spiculation_label)  \n",
    "        margin_list.append(margin_label);              sphericiy_list.append(sphericiy_label);   malignacy_list.append(malignacy_label)  \n",
    "        \n",
    "        batch_counter += 1\n",
    "        \n",
    "        if batch_counter >= batch_size:\n",
    "            \n",
    "            x = numpy.vstack(img_list);                     y_diamter = numpy.vstack(diameter_list)\n",
    "            y_malignacy = numpy.vstack(malignacy_list);     y_sphericiy = numpy.vstack(sphericiy_list);   y_margin = numpy.vstack(margin_list)\n",
    "            y_spiculation = numpy.vstack(spiculation_list); y_texture = numpy.vstack(texture_list);       y_calcification = numpy.vstack(calcification_list)\n",
    "            y_subtlety = numpy.vstack(subtlety_list);       y_lobulation = numpy.vstack(lobulation_list); y_internal_structure = numpy.vstack(internal_structure_list)\n",
    "\n",
    "            yield x, {\"out_diamter\": y_diamter, \"out_malignancy\": y_malignacy, \"out_sphericiy\": y_sphericiy, \"out_margin\": y_margin, \"out_spiculation\": y_spiculation, \"out_texture\": y_texture, \"out_calcification\": y_calcification, \"out_internal_structure\": y_internal_structure, \"out_lobulation\": y_lobulation, \"out_subtlety\": y_subtlety }\n",
    "            \n",
    "            subtlety_list = [];      lobulation_list = []; internal_structure_list = []\n",
    "            calcification_list = []; texture_list = [];    spiculation_list = []\n",
    "            margin_list = [];        sphericiy_list = [];  malignacy_list = []\n",
    "            img_list = [];           diameter_list = [];   batch_counter = 0\n",
    "\n",
    "def load_cube_img(src_path, rows, cols, size):\n",
    "    \n",
    "    img = cv2.imread(src_path, cv2.IMREAD_GRAYSCALE)\n",
    "    res = numpy.zeros((rows * cols, size, size))\n",
    "\n",
    "    img_height = size\n",
    "    img_width = size\n",
    "\n",
    "    for row in range(rows):\n",
    "        \n",
    "        for col in range(cols):\n",
    "            \n",
    "            src_y = row * img_height\n",
    "            src_x = col * img_width\n",
    "            res[row * cols + col] = img[src_y:src_y + img_height, src_x:src_x + img_width]\n",
    "\n",
    "    return res\n",
    "\n",
    "def normalize_and_expand(img):\n",
    "    \n",
    "    img = img.astype(numpy.float32)\n",
    "    img -= 41  # 41 is MEAN_PIXEL_VALUE\n",
    "    img /= 255.\n",
    "    img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2], 1)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3984df14-0561-4108-928d-be6d79593a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    \n",
    "    res = 0.001\n",
    "    \n",
    "    if epoch > 5:\n",
    "        \n",
    "        res = 0.0001\n",
    "        \n",
    "    print(\"learnrate: \", res, \" epoch: \", epoch)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc5e6b-abc7-45ce-91ea-010dc0aac9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(input_shape=(32, 32, 32, 1), load_weight_path=None) -> Model: \n",
    "    \n",
    "    inputs = Input(shape=input_shape, name=\"input_1\")\n",
    "    x = inputs\n",
    "    x = AveragePooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), border_mode=\"same\")(x)\n",
    "    x = Convolution3D(64, 3, 3, 3, activation='relu', border_mode='same', name='conv1', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), border_mode='valid', name='pool1')(x)\n",
    "\n",
    "    # 2nd layer group\n",
    "    x = Convolution3D(128, 3, 3, 3, activation='relu', border_mode='same', name='conv2', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool2')(x)\n",
    "\n",
    "    # 3rd layer group\n",
    "    x = Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3a', subsample=(1, 1, 1))(x)\n",
    "    x = Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3b', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool3')(x)\n",
    "\n",
    "    # 4th layer group\n",
    "    x = Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv4a', subsample=(1, 1, 1))(x)\n",
    "    x = Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv4b', subsample=(1, 1, 1),)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool4')(x)\n",
    "\n",
    "    # output\n",
    "    last64 = Convolution3D(64, 2, 2, 2, activation=\"relu\", name=\"last_64\")(x)\n",
    "    out_attribute = Convolution3D(1, 1, 1, 1, activation=None, name=\"out_attribute_last\")(last64)\n",
    "    out_attribute = Flatten(name=\"out_texture\")(out_attribute)\n",
    "\n",
    "    model = Model(input=inputs, output=out_attribute)\n",
    "    \n",
    "    if load_weight_path is not None: model.load_weights(load_weight_path, by_name=False)\n",
    "\n",
    "    optimizer = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "    loss = {\"out_texture\": \"mean_absolute_error\"}\n",
    "    metrics = {\"out_texture\": [mean_absolute_error]}\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    model.summary(line_length=140)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c8cda4-c9f8-495d-ab79-2bf55239e591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843cbcb-4ed8-4a86-90ff-f0308b92224d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
