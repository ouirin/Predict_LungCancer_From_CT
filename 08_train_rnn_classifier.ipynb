{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624be280-a9eb-4e1b-bf57-b4ba2cd8aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import ntpath\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import binary_accuracy, binary_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.layers import Input, GRU, Dense, multiply, Flatten, TimeDistributed\n",
    "from keras.layers.core import Permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea09f5b-0f8f-4455-bbc0-056c8b514781",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "trainset, testset = load_data()\n",
    "\n",
    "train_gen = data_generator(batch_size, trainset, need_augment=True)\n",
    "\n",
    "test_gen = data_generator(batch_size, testset, need_augment=False)\n",
    "\n",
    "learnrate_scheduler = LearningRateScheduler(step_decay)\n",
    "\n",
    "model = get_net(load_weight_path=None)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"G:/LungCancerPredict/model/\" + \"{epoch:02d}-{val_loss:.4f}.hd5\", monitor='val_loss', period=1)\n",
    "\n",
    "model.fit_generator(train_gen, int(len(trainset)/batch_size), 10, validation_data=test_gen, nb_val_samples=int(len(testset)/batch_size), callbacks=[checkpoint, learnrate_scheduler])\n",
    "\n",
    "model.save(\"G:/LungCancerPredict/model/the_end.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660cd28b-6146-4bdf-8538-d477d684a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_ratio=20, neg_per_pos=20):\n",
    "    \n",
    "    #load positive\n",
    "    pos_samples = glob.glob(\"G:/LungCancerPredict/generated/luna16_positive_cube/*.png\")\n",
    "    random.shuffle(pos_samples)\n",
    "\n",
    "    #load negative\n",
    "    neg_samples_tn = glob.glob(\"G:/LungCancerPredict/generated/luna16_negative_cube/*_tn.png\")\n",
    "    neg_samples_fp = glob.glob(\"G:/LungCancerPredict/generated/luna16_negative_cube/*_fp.png\")\n",
    "    neg_samples_candidates = glob.glob(\"G:/LungCancerPredict/generated/luna16_negative_cube/*_candidates.png\")\n",
    "    neg_samples = neg_samples_fp + neg_samples_tn + neg_samples_candidates + neg_samples_candidates + neg_samples_candidates\n",
    "    random.shuffle(neg_samples)\n",
    "\n",
    "    # 正负样本混合\n",
    "    pos_index = 0\n",
    "    dataset = []\n",
    "    for index, neg_sample in enumerate(neg_samples):\n",
    "        \n",
    "        dataset.append((neg_sample, 0, 0))\n",
    "        \n",
    "        if index % neg_per_pos == 0:\n",
    "            \n",
    "            pos_sample = pos_samples[pos_index]\n",
    "            \n",
    "            file_name = ntpath.basename(pos_sample)\n",
    "            \n",
    "            parts = file_name.split(\"_\")\n",
    "            class_label = int(parts[-2])\n",
    "            size_label = int(parts[-3])\n",
    "            \n",
    "            dataset.append((pos_sample, class_label, size_label))\n",
    "            pos_index += 1\n",
    "            pos_index %= len(pos_samples)\n",
    "\n",
    "    random.shuffle(dataset)\n",
    "    counter = int(len(dataset) * ((100-test_ratio) / 100.0))\n",
    "    dataset_train = dataset\n",
    "    dataset_test = dataset[counter:]\n",
    "                \n",
    "    print(\"Train count: \", len(dataset_train), \", holdout count: \", len(dataset_test))\n",
    "    \n",
    "    return dataset_train, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e07ebd-7244-4646-9e05-cef55f453b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size, record_list, need_augment):\n",
    "\n",
    "    random_state = numpy.random.RandomState(999)\n",
    "    \n",
    "    if need_augment: random.shuffle(record_list)\n",
    "\n",
    "    #按照batch_size动态生成数据\n",
    "    batch_counter, crop_size, img_list, class_list, size_list = 0, 32, [], [], []\n",
    "        \n",
    "    for index, record in enumerate(record_list):\n",
    "        \n",
    "        class_label, size_label = record[1], record[2]\n",
    "        \n",
    "        if class_label == 0:\n",
    "            \n",
    "            cube_image = load_cube_img(record[0], 6, 8, 48)\n",
    "\n",
    "            indent_x, indent_y, indent_z = 0, 0, 0\n",
    "          \n",
    "            wiggle = 48 - crop_size - 1\n",
    "\n",
    "            indent_x, indent_y, indent_z = (random.randint(0, wiggle) for _ in range(3))\n",
    "\n",
    "            cube_image = cube_image[indent_z:indent_z + crop_size, indent_y:indent_y + crop_size, indent_x:indent_x + crop_size]\n",
    "        \n",
    "            if need_augment:   \n",
    "                if random.randint(0, 100) > 50: cube_image = numpy.fliplr(cube_image)\n",
    "                if random.randint(0, 100) > 50: cube_image = numpy.flipud(cube_image)\n",
    "                if random.randint(0, 100) > 50: cube_image = cube_image[:, :, ::-1]\n",
    "                if random.randint(0, 100) > 50: cube_image = cube_image[:, ::-1, :]\n",
    "\n",
    "        if class_label == 1:\n",
    "            \n",
    "            cube_image = load_cube_img(record[0], 8, 8, 64)\n",
    "            \n",
    "            if need_augment:\n",
    "                wiggle_indent = crop_size / 4\n",
    "                wiggle = 64 - crop_size - crop_size / 2 - 1\n",
    "                indent_x = int(wiggle_indent + random.randint(0, wiggle))\n",
    "                indent_y = int(wiggle_indent + random.randint(0, wiggle))\n",
    "                indent_z = int(wiggle_indent + random.randint(0, wiggle))\n",
    "            else:\n",
    "                indent_x = int((64 - crop_size) / 2)\n",
    "                indent_y = int((64 - crop_size) / 2)\n",
    "                indent_z = int((64 - crop_size) / 2)\n",
    "\n",
    "            cube_image = cube_image[indent_z:indent_z + crop_size, indent_y:indent_y + crop_size, indent_x:indent_x + crop_size]\n",
    "\n",
    "            if need_augment:\n",
    "                if random.randint(0, 100) > 50: cube_image = numpy.fliplr(cube_image)\n",
    "                if random.randint(0, 100) > 50: cube_image = numpy.flipud(cube_image)\n",
    "                if random.randint(0, 100) > 50: cube_image = cube_image[:, :, ::-1]\n",
    "                if random.randint(0, 100) > 50: cube_image = cube_image[:, ::-1, :]\n",
    "                    \n",
    "        img3d = normalize_and_expand(cube_image)\n",
    "\n",
    "        img_list.append(img3d), class_list.append(class_label), size_list.append(size_label)\n",
    "\n",
    "        batch_counter += 1\n",
    "        \n",
    "        if batch_counter >= batch_size:\n",
    "            \n",
    "            x, y_class, y_size = numpy.vstack(img_list), numpy.vstack(class_list), numpy.vstack(size_list)\n",
    "\n",
    "            yield x, {\"out_class\": y_class, \"out_malignancy\": y_size}\n",
    "            \n",
    "            img_list, class_list, size_list = [], [], []\n",
    "            \n",
    "            batch_counter = 0\n",
    "\n",
    "def load_cube_img(src_path, rows, cols, size):\n",
    "    \n",
    "    img = cv2.imread(src_path, cv2.IMREAD_GRAYSCALE)\n",
    "    res = numpy.zeros((rows * cols, size, size))\n",
    "\n",
    "    img_height = size\n",
    "    img_width = size\n",
    "\n",
    "    for row in range(rows):\n",
    "        \n",
    "        for col in range(cols):\n",
    "            \n",
    "            src_y = row * img_height\n",
    "            src_x = col * img_width\n",
    "            res[row * cols + col] = img[src_y:src_y + img_height, src_x:src_x + img_width]\n",
    "\n",
    "    return res\n",
    "\n",
    "def normalize_and_expand(img):\n",
    "    \n",
    "    img = img.astype(numpy.float32)\n",
    "    img -= 41 # 41 is MEAN_PIXEL_VALUE\n",
    "    img /= 255.\n",
    "    \n",
    "    imgN=numpy.zeros(shape=(16,32,32))\n",
    "\n",
    "    for i in range(16):\n",
    "    \n",
    "        imgN[i]=(img[2*i]+img[2*i+1])/2\n",
    "        \n",
    "    imgN = imgN.reshape(1,8,8,8,32)\n",
    "    \n",
    "    return imgN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef14c0f-66b4-4c40-ba91-85928413c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    \n",
    "    res = 0.001\n",
    "    \n",
    "    if epoch > 5:\n",
    "        \n",
    "        res = 0.0001\n",
    "        \n",
    "    print(\"learnrate: \", res, \" epoch: \", epoch)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e2c661-6e9d-442d-b12c-611014f8b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(load_weight_path=None) -> Model:\n",
    "        \n",
    "    input_shapeT1=(8,32)  \n",
    "    input1 = Input( shape=input_shapeT1 ) \n",
    "    gru1 = GRU(128,activation='tanh', recurrent_activation='sigmoid',return_sequences=True)(input1)\n",
    "    gru1 = attention_block(gru1)\n",
    "    gru1 = Flatten()(gru1)\n",
    "    Encoder1 = Model(input1, gru1)\n",
    "\n",
    "    input_shapeT2=(8,8,32)\n",
    "    input2 = Input( shape=input_shapeT2 )\n",
    "    embed2 = TimeDistributed(Encoder1)(input2)\n",
    "    gru2 = GRU(256,activation='tanh', recurrent_activation='sigmoid',return_sequences=True)(embed2)\n",
    "    gru2 = attention_block(gru2)\n",
    "    gru2 = Flatten()(gru2)\n",
    "    Encoder2 = Model(input2, gru2)\n",
    "    \n",
    "    input_shapeT3=(8,8,8,32) \n",
    "    input3 = Input( shape=input_shapeT3 )\n",
    "    embed3 = TimeDistributed(Encoder2)(input3)\n",
    "    gru3 = GRU(512,activation='tanh', recurrent_activation='sigmoid',return_sequences=True)(embed3)\n",
    "    gru3 = attention_block(gru3)\n",
    "    gru3 = Flatten()(gru3)\n",
    "   \n",
    "    gru3 = Dense(512, activation='relu')(gru3)\n",
    "    out_class = Dense(1, activation='sigmoid', name='out_class')(gru3)\n",
    "    model = Model(input=input3, output=out_class)\n",
    "  \n",
    "    if load_weight_path is not None: model.load_weights(load_weight_path, by_name=False)\n",
    "\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.9, epsilon=1e-08, amsgrad=True)\n",
    "    loss = {\"out_class\": \"binary_crossentropy\"}\n",
    "    metrics = {\"out_class\": [binary_accuracy, binary_crossentropy]}\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    model.summary(line_length=140)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def attention_block(inputs):\n",
    "    \n",
    "    a = Permute((2, 1))(inputs)\n",
    "    \n",
    "    a = Dense(8, activation='softmax')(a)\n",
    "    \n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "   \n",
    "    output_attention_mul = multiply([inputs, a_probs], name='attention_mul')\n",
    "    \n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f4539-4ef5-46c6-8669-84b1da627de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7962cc-21ce-4a21-ab27-87fe985f11cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03ab89-9b11-4e74-9726-965a9ff68ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da737a3-dea0-4fc1-9d0c-84f071e6fc89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
