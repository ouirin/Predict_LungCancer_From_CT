{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a5ffb-f4b7-46b6-ae8f-f07bf5f7d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import ntpath\n",
    "import numpy\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56622a33-d51e-4de7-94d7-8043f53edb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_nodule_attribute()\n",
    "\n",
    "ndsb_list = os.listdir(\"G:/LungCancerPredict/extracted/ndsb3_extracted_images/\")\n",
    "res_list = pandas.read_csv(\"G:/LungCancerPredict/detected/cnn_detect_ndsb3_nms_cube_attribute/res_list.csv\")\n",
    "\n",
    "count=0\n",
    "\n",
    "for patient_id in ndsb_list:\n",
    "    \n",
    "    df = res_list.loc[res_list[\"patient_id\"]==patient_id ]\n",
    "    \n",
    "    df.to_csv(\"G:/LungCancerPredict/detected/cnn_detect_ndsb3_nms_cube_attribute/\" + patient_id + \".csv\", index=False)\n",
    "    \n",
    "    count+=1\n",
    "    \n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e57ab35-d503-40c3-b8d6-3ca90333ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_nodule_attribute():\n",
    "    \n",
    "    csv_target_path = \"G:/LungCancerPredict/detected/cnn_detect_ndsb3_nms_cube_attribute/res_list.csv\"\n",
    "\n",
    "    model_path_texture       = \"G:/LungCancerPredict/model/out_texture.hd5\"\n",
    "    model_path_subtlety      = \"G:/LungCancerPredict/model/out_subtlety.hd5\"\n",
    "    model_path_spiculation   = \"G:/LungCancerPredict/model/out_spiculation.hd5\"\n",
    "    model_path_sphericiy     = \"G:/LungCancerPredict/model/out_sphericiy.hd5\"\n",
    "    model_path_margin        = \"G:/LungCancerPredict/model/out_margin.hd5\"\n",
    "    model_path_malignancy    = \"G:/LungCancerPredict/model/out_malignancy.hd5\"\n",
    "    model_path_lobulation    = \"G:/LungCancerPredict/model/out_lobulation.hd5\"\n",
    "    model_path_diamter       = \"G:/LungCancerPredict/model/out_diamter.hd5\"\n",
    "    model_path_calcification = \"G:/LungCancerPredict/model/out_calcification.hd5\"\n",
    "\n",
    "    model_texture       = get_net(load_weight_path=model_path_texture)\n",
    "    model_subtlety      = get_net(load_weight_path=model_path_subtlety)\n",
    "    model_spiculation   = get_net(load_weight_path=model_path_spiculation)\n",
    "    model_sphericiy     = get_net(load_weight_path=model_path_sphericiy)\n",
    "    model_margin        = get_net(load_weight_path=model_path_margin)\n",
    "    model_malignancy    = get_net(load_weight_path=model_path_malignancy)\n",
    "    model_lobulation    = get_net(load_weight_path=model_path_lobulation)\n",
    "    model_diamter       = get_net(load_weight_path=model_path_diamter)\n",
    "    model_calcification = get_net(load_weight_path=model_path_calcification)\n",
    "    \n",
    "    samples = glob.glob(\"G:/LungCancerPredict/detected/cnn_detect_ndsb3_nms_cube/*.png\")\n",
    "    print(len(samples))\n",
    "    \n",
    "    #按照batch_size进行预测\n",
    "    batch_img_list = []; batch_info_list = []; res_list = []\n",
    "    batch_size = 32; done_count = 0; crop_size = 32\n",
    "\n",
    "    for index, sample in enumerate(samples):\n",
    "\n",
    "        print(index)\n",
    "\n",
    "        file_name = ntpath.basename(sample)\n",
    "\n",
    "        parts = file_name.split(\"_\")\n",
    "        \n",
    "        chance = parts[-3]; z = parts[-4]; y = parts[-5]; x = parts[-6]; patient_id = parts[-8]\n",
    "        \n",
    "        batch_info_list.append((patient_id,x,y,z,chance))\n",
    "\n",
    "        cube_image = load_cube_img(sample, 8, 8, 64)\n",
    "\n",
    "        indent_x = int((64 - crop_size) / 2)\n",
    "        indent_y = int((64 - crop_size) / 2)\n",
    "        indent_z = int((64 - crop_size) / 2)\n",
    "\n",
    "        cube_image = cube_image[indent_z:indent_z + crop_size, indent_y:indent_y + crop_size, indent_x:indent_x + crop_size]\n",
    "\n",
    "        img3d = normalize_and_expand(cube_image)\n",
    "\n",
    "        batch_img_list.append(img3d)\n",
    "     \n",
    "        done_count += 1\n",
    "\n",
    "        if len(batch_img_list)% batch_size==0 or done_count==len(samples):\n",
    "\n",
    "            batch_data = numpy.vstack(batch_img_list)\n",
    "            p_diamter = model_diamter.predict(batch_data, batch_size=batch_size)\n",
    "            p_malignancy = model_malignancy.predict(batch_data, batch_size=batch_size)\n",
    "            p_spiculation = model_spiculation.predict(batch_data, batch_size=batch_size)\n",
    "            p_lobulation = model_lobulation.predict(batch_data, batch_size=batch_size)\n",
    "            p_sphericiy = model_sphericiy.predict(batch_data, batch_size=batch_size)\n",
    "            p_margin = model_margin.predict(batch_data, batch_size=batch_size)\n",
    "            p_subtlety = model_subtlety.predict(batch_data, batch_size=batch_size)\n",
    "            p_texture = model_texture.predict(batch_data, batch_size=batch_size)\n",
    "            p_calcification = model_calcification.predict(batch_data, batch_size=batch_size)\n",
    "            \n",
    "            for i in range(len(p_diamter)):\n",
    "                \n",
    "                diamter = str(p_diamter[i][0]);       malignancy = str(p_malignancy[i][0]); spiculation = str(p_spiculation[i][0])\n",
    "                lobulation = str(p_lobulation[i][0]); sphericiy = str(p_sphericiy[i][0]);   margin = str(p_margin[i][0])\n",
    "                subtley = str(p_subtlety[i][0]);      textrue = str(p_texture[i][0]);       calcification = str(p_calcification[i][0])\n",
    "\n",
    "                patient_id=batch_info_list[i][0]; chance = batch_info_list[i][4]\n",
    "                \n",
    "                x = batch_info_list[i][1]; y = batch_info_list[i][2]; z = batch_info_list[i][3]\n",
    "                \n",
    "                csv_line = [patient_id, x, y, z, chance,diamter,malignancy,spiculation,lobulation,sphericiy,margin,subtley,textrue,calcification]\n",
    "                \n",
    "                res_list.append(csv_line)\n",
    "            \n",
    "            batch_img_list = []; batch_info_list = []\n",
    "    \n",
    "    df = pandas.DataFrame(res_list, columns=[\"patient_id\", \"coord_x\", \"coord_y\", \"coord_z\", \"nodule_chance\",\"diamter\",\"malignancy\",\"spiculation\",\"lobulation\",\"sphericiy\",\"margin\",\"subtley\",\"textrue\",\"calcification\"])\n",
    "    df.to_csv(csv_target_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "def load_cube_img(src_path, rows, cols, size):\n",
    "    \n",
    "    img = cv2.imread(src_path, cv2.IMREAD_GRAYSCALE)\n",
    "    res = numpy.zeros((rows * cols, size, size))\n",
    "\n",
    "    img_height = size\n",
    "    img_width = size\n",
    "\n",
    "    for row in range(rows):\n",
    "        \n",
    "        for col in range(cols):\n",
    "            \n",
    "            src_y = row * img_height\n",
    "            src_x = col * img_width\n",
    "            res[row * cols + col] = img[src_y:src_y + img_height, src_x:src_x + img_width]\n",
    "\n",
    "    return res\n",
    "\n",
    "def normalize_and_expand(img):\n",
    "    \n",
    "    img = img.astype(numpy.float32)\n",
    "    img -= 41  # 41 is MEAN_PIXEL_VALUE\n",
    "    img /= 255.\n",
    "    img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2], 1)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce833db-32e3-4110-ba09-9d92783f8f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.optimizers import SGD \n",
    "from keras.metrics import mean_absolute_error\n",
    "from keras.layers import Input, AveragePooling3D, Convolution3D, MaxPooling3D, Flatten\n",
    "\n",
    "def get_net(input_shape=(32, 32, 32, 1), load_weight_path=None) -> Model: \n",
    "    \n",
    "    inputs = Input(shape=input_shape, name=\"input_1\")\n",
    "    x = inputs\n",
    "    x = AveragePooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), border_mode=\"same\")(x)\n",
    "    x = Convolution3D(64, 3, 3, 3, activation='relu', border_mode='same', name='conv1', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), border_mode='valid', name='pool1')(x)\n",
    "\n",
    "    # 2nd layer group\n",
    "    x = Convolution3D(128, 3, 3, 3, activation='relu', border_mode='same', name='conv2', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool2')(x)\n",
    "\n",
    "    # 3rd layer group\n",
    "    x = Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3a', subsample=(1, 1, 1))(x)\n",
    "    x = Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3b', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool3')(x)\n",
    "\n",
    "    # 4th layer group\n",
    "    x = Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv4a', subsample=(1, 1, 1))(x)\n",
    "    x = Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv4b', subsample=(1, 1, 1),)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool4')(x)\n",
    "\n",
    "    # output\n",
    "    last64 = Convolution3D(64, 2, 2, 2, activation=\"relu\", name=\"last_64\")(x)\n",
    "    out_attribute = Convolution3D(1, 1, 1, 1, activation=None, name=\"out_attribute_last\")(last64)\n",
    "    out_attribute = Flatten(name=\"out_texture\")(out_attribute)\n",
    "\n",
    "    model = Model(input=inputs, output=out_attribute)\n",
    "    \n",
    "    if load_weight_path is not None: model.load_weights(load_weight_path, by_name=False)\n",
    "\n",
    "    optimizer = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "    loss = {\"out_texture\": \"mean_absolute_error\"}\n",
    "    metrics = {\"out_texture\": [mean_absolute_error]}\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    model.summary(line_length=140)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a80e874-06dc-4707-9348-23a57b408e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121bb6fb-2536-4b52-a4a3-536859d8a384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
