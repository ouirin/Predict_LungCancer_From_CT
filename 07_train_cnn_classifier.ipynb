{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a91a6-d10e-44e5-a1d8-3ed40357004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import ntpath\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD \n",
    "from keras.metrics import binary_accuracy, binary_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.layers import Input, AveragePooling3D, Convolution3D, MaxPooling3D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc60989-8dd6-427a-9467-64428dfc125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "trainset, testset = load_data()\n",
    "\n",
    "train_gen = data_generator(batch_size, trainset, need_augment=True)\n",
    "\n",
    "test_gen = data_generator(batch_size, testset, need_augment=False)\n",
    "\n",
    "learnrate_scheduler = LearningRateScheduler(step_decay)\n",
    "\n",
    "model = get_net(load_weight_path=None)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"G:/LungCancerPredict/model/\" + \"{epoch:02d}-{val_loss:.4f}.hd5\", monitor='val_loss', period=1)\n",
    "\n",
    "model.fit_generator(train_gen, int(len(trainset)/batch_size), 10, validation_data=test_gen, nb_val_samples=int(len(testset)/batch_size), callbacks=[checkpoint, learnrate_scheduler])\n",
    "\n",
    "model.save(\"G:/LungCancerPredict/model/the_end.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf9174-6d31-4939-b7a0-1d905951545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_ratio=20, neg_per_pos=20):\n",
    "    \n",
    "    #load positive\n",
    "    pos_samples = glob.glob(\"G:/LungCancerPredict/generated/luna16_positive_cube/*.png\")\n",
    "    random.shuffle(pos_samples)\n",
    "    print(len(pos_samples))\n",
    "\n",
    "    #load negative\n",
    "    neg_samples_tn = glob.glob(\"G:/LungCancerPredict/generated/luna16_negative_cube/*_tn.png\")\n",
    "    print(len(neg_samples_tn))\n",
    "    neg_samples_fp = glob.glob(\"G:/LungCancerPredict/generated/luna16_negative_cube/*_fp.png\")\n",
    "    print(len(neg_samples_fp))\n",
    "    neg_samples_candidates = glob.glob(\"G:/LungCancerPredict/generated/luna16_negative_cube/*_candidates.png\")\n",
    "    print(len(neg_samples_candidates))\n",
    "    neg_samples = neg_samples_fp + neg_samples_tn + neg_samples_candidates + neg_samples_candidates + neg_samples_candidates\n",
    "    random.shuffle(neg_samples)\n",
    "    print(len(neg_samples))\n",
    "\n",
    "    # 正负样本混合\n",
    "    pos_index = 0\n",
    "    dataset = []\n",
    "    for index, neg_sample in enumerate(neg_samples):\n",
    "        \n",
    "        dataset.append((neg_sample, 0, 0))\n",
    "        \n",
    "        if index % neg_per_pos == 0:\n",
    "            \n",
    "            pos_sample = pos_samples[pos_index]\n",
    "            \n",
    "            file_name = ntpath.basename(pos_sample)\n",
    "            \n",
    "            parts = file_name.split(\"_\")\n",
    "            class_label = int(parts[-2])\n",
    "            size_label = int(parts[-3])\n",
    "            \n",
    "            dataset.append((pos_sample, class_label, size_label))\n",
    "            pos_index += 1\n",
    "            pos_index %= len(pos_samples)\n",
    "\n",
    "    random.shuffle(dataset)\n",
    "    counter = int(len(dataset) * ((100-test_ratio) / 100.0))\n",
    "    dataset_train = dataset\n",
    "    dataset_test = dataset[counter:]\n",
    "                \n",
    "    print(\"Train count: \", len(dataset_train), \", Test count: \", len(dataset_test))\n",
    "    \n",
    "    return dataset_train, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a4eb60-e57a-415e-8645-2d4674d3e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size, record_list, need_augment):\n",
    "\n",
    "    random_state = numpy.random.RandomState(999)\n",
    "    \n",
    "    if need_augment: random.shuffle(record_list)\n",
    "\n",
    "    #按照batch_size动态生成数据\n",
    "    batch_counter, crop_size, img_list, class_list, size_list = 0, 32, [], [], []\n",
    "        \n",
    "    for index, record in enumerate(record_list):\n",
    "        \n",
    "        class_label, size_label = record[1], record[2]\n",
    "        \n",
    "        if class_label == 0:\n",
    "            \n",
    "            cube_image = load_cube_img(record[0], 6, 8, 48)\n",
    "\n",
    "            indent_x, indent_y, indent_z = 0, 0, 0\n",
    "          \n",
    "            wiggle = 48 - crop_size - 1\n",
    "\n",
    "            indent_x, indent_y, indent_z = (random.randint(0, wiggle) for _ in range(3))\n",
    "\n",
    "            cube_image = cube_image[indent_z:indent_z + crop_size, indent_y:indent_y + crop_size, indent_x:indent_x + crop_size]\n",
    "        \n",
    "            if need_augment:   \n",
    "                if random.randint(0, 100) > 50: cube_image = numpy.fliplr(cube_image)\n",
    "                if random.randint(0, 100) > 50: cube_image = numpy.flipud(cube_image)\n",
    "                if random.randint(0, 100) > 50: cube_image = cube_image[:, :, ::-1]\n",
    "                if random.randint(0, 100) > 50: cube_image = cube_image[:, ::-1, :]\n",
    "\n",
    "        if class_label == 1:\n",
    "            \n",
    "            cube_image = load_cube_img(record[0], 8, 8, 64)\n",
    "            \n",
    "            if need_augment:\n",
    "                wiggle_indent = crop_size / 4\n",
    "                wiggle = 64 - crop_size - crop_size / 2 - 1\n",
    "                indent_x = int(wiggle_indent + random.randint(0, wiggle))\n",
    "                indent_y = int(wiggle_indent + random.randint(0, wiggle))\n",
    "                indent_z = int(wiggle_indent + random.randint(0, wiggle))\n",
    "            else:\n",
    "                indent_x = int((64 - crop_size) / 2)\n",
    "                indent_y = int((64 - crop_size) / 2)\n",
    "                indent_z = int((64 - crop_size) / 2)\n",
    "\n",
    "            cube_image = cube_image[indent_z:indent_z + crop_size, indent_y:indent_y + crop_size, indent_x:indent_x + crop_size]\n",
    "\n",
    "            if need_augment:\n",
    "                if random.randint(0, 100) > 50: cube_image = numpy.fliplr(cube_image)\n",
    "                if random.randint(0, 100) > 50: cube_image = numpy.flipud(cube_image)\n",
    "                if random.randint(0, 100) > 50: cube_image = cube_image[:, :, ::-1]\n",
    "                if random.randint(0, 100) > 50: cube_image = cube_image[:, ::-1, :]\n",
    "                    \n",
    "        img3d = normalize_and_expand(cube_image)\n",
    "\n",
    "        img_list.append(img3d), class_list.append(class_label), size_list.append(size_label)\n",
    "\n",
    "        batch_counter += 1\n",
    "        \n",
    "        if batch_counter >= batch_size:\n",
    "            \n",
    "            x, y_class, y_size = numpy.vstack(img_list), numpy.vstack(class_list), numpy.vstack(size_list)\n",
    "\n",
    "            yield x, {\"out_class\": y_class, \"out_malignancy\": y_size}\n",
    "            \n",
    "            img_list, class_list, size_list = [], [], []\n",
    "            \n",
    "            batch_counter = 0\n",
    "\n",
    "def load_cube_img(src_path, rows, cols, size):\n",
    "    \n",
    "    img = cv2.imread(src_path, cv2.IMREAD_GRAYSCALE)\n",
    "    res = numpy.zeros((rows * cols, size, size))\n",
    "\n",
    "    img_height = size\n",
    "    img_width = size\n",
    "\n",
    "    for row in range(rows):\n",
    "        \n",
    "        for col in range(cols):\n",
    "            \n",
    "            src_y = row * img_height\n",
    "            src_x = col * img_width\n",
    "            res[row * cols + col] = img[src_y:src_y + img_height, src_x:src_x + img_width]\n",
    "\n",
    "    return res\n",
    "\n",
    "def normalize_and_expand(img):\n",
    "    \n",
    "    img = img.astype(numpy.float32)\n",
    "    img -= 41  # 41 is MEAN_PIXEL_VALUE\n",
    "    img /= 255.\n",
    "    img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2], 1)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c8d75-277d-40b8-9d1a-28fe4b398ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    \n",
    "    res = 0.001\n",
    "    \n",
    "    if epoch > 5:\n",
    "        \n",
    "        res = 0.0001\n",
    "        \n",
    "    print(\"learnrate: \", res, \" epoch: \", epoch)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce6655-04f8-4502-9e31-e52a295fce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(input_shape=(32, 32, 32, 1), load_weight_path=None) -> Model:  \n",
    "    \n",
    "    inputs = Input(shape=input_shape, name=\"input_1\")\n",
    "    x = inputs\n",
    "    x = AveragePooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), border_mode=\"same\")(x)\n",
    "    x = Convolution3D(64, 3, 3, 3, activation='relu', border_mode='same', name='conv1', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), border_mode='valid', name='pool1')(x)\n",
    "\n",
    "    # 2nd layer group\n",
    "    x = Convolution3D(128, 3, 3, 3, activation='relu', border_mode='same', name='conv2', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool2')(x)\n",
    "\n",
    "    # 3rd layer group\n",
    "    x = Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3a', subsample=(1, 1, 1))(x)\n",
    "    x = Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3b', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool3')(x)\n",
    "\n",
    "    # 4th layer group\n",
    "    x = Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv4a', subsample=(1, 1, 1))(x)\n",
    "    x = Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv4b', subsample=(1, 1, 1),)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool4')(x)\n",
    "\n",
    "    # output\n",
    "    last64 = Convolution3D(64, 2, 2, 2, activation=\"relu\", name=\"last_64\")(x)\n",
    "    out_class = Convolution3D(1, 1, 1, 1, activation=\"sigmoid\", name=\"out_class_last\")(last64)\n",
    "    out_class = Flatten(name=\"out_class\")(out_class)\n",
    "\n",
    "    model = Model(input=inputs, output=out_class)\n",
    "    \n",
    "    if load_weight_path is not None: model.load_weights(load_weight_path, by_name=False)\n",
    "    \n",
    "    optimizer = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "    loss = {\"out_class\": \"binary_crossentropy\"}\n",
    "    metrics = {\"out_class\": [binary_accuracy, binary_crossentropy]}\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    model.summary(line_length=140)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577703bd-8ff7-4dab-82e0-d268525630ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164aed5f-96ef-461d-a165-697dac2851b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d81a0-b2c9-4a6b-9c1e-f278170d9f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
